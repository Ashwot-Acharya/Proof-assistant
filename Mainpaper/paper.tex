\documentclass[12pt]{article}

\usepackage[utf8]{inputenc}
\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{cite}
\usepackage{geometry}
\usepackage{bussproofs}
\usepackage{braket}
\geometry{a4paper, margin=1in}
\usepackage{titlesec}
\usepackage{newunicodechar}
\usepackage{tikz}
\DeclareUnicodeCharacter{2200}{\ensuremath{\forall}}    % ∀
\DeclareUnicodeCharacter{2113}{\ensuremath{\ell}}       % ℓ
\DeclareUnicodeCharacter{2192}{\ensuremath{\rightarrow}}% →
\DeclareUnicodeCharacter{00D7}{\ensuremath{\times}}     % ×
\DeclareUnicodeCharacter{228E}{\ensuremath{\uplus}}   % ⊎
\DeclareUnicodeCharacter{22A5}{\ensuremath{\bot}}       % ⊥
\DeclareUnicodeCharacter{00AC}{\ensuremath{\neg}}       % ¬
\DeclareUnicodeCharacter{2081}{\textsubscript{1}}       % ₁
\DeclareUnicodeCharacter{2082}{\textsubscript{2}}       % ₂
\DeclareUnicodeCharacter{03BB}{\ensuremath{\lambda}}    % λ
\DeclareUnicodeCharacter{03A3}{\ensuremath{\Sigma}}   % Σ
\geometry{
  left=1.2in,
  right=1.2in,
  top=1.1in,
  bottom=1.1in
}
\usetikzlibrary{arrows.meta, positioning}
\titleformat{\section}{\large\bfseries}{\thesection}{1em}{}
\titleformat{\subsection}{\normalsize\bfseries}{\thesubsection}{1em}{}

\title{Working Principles of Proof Assistants and Formalization of some proofs in Agda}
\author{Bishesh Bohora, Supreme Chaudhary, Ashwot Acharya \\
\small Kathmandu University 
\small \texttt{}
}
\date{\today}

\begin{document}

\begin{titlepage}
    \begin{center}
        % Title
        \Large\bfseries
        Working Principles of Proof Assistants and Formalization of some proofs in Agda\\[2cm]
        
        \normalsize
        SECOND YEAR PROJECT REPORT\\[2ex]
        
        \small
        SUBMITTED IN PARTIAL FULFILLMENT OF THE REQUIREMENTS FOR\\
        THE DEGREE OF BSC. IN COMPUTATIONAL MATHEMATICS\\[2cm]
        
        \normalsize
        BY\\[2ex]
        \textbf{Ashwot Acharya, Bishesh Bohora, Supreme Chaudhary}\\[2cm]
        
        \includegraphics[width=4cm]{logo.png}\\[2cm]
        % Replace with your logo file. Place 'ku_logo.png' in the same folder!
        
        DEPARTMENT OF MATHEMATICS\\
        KATHMANDU UNIVERSITY\\
        DHULIKHEL, NEPAL\\[2ex]
                
        \vfill
    \end{center}
\end{titlepage}

\thispagestyle{empty}

\begin{center}
    \textbf{\LARGE CERTIFICATION}
\end{center}

\vspace{1em}

This project entitled ``\textbf{Working Principles of Proof Assistants and Formalization of some proofs in Agda}'' is carried out under our supervision for the specified entire period satisfactorily and is hereby certified as a work done by the following students:
\begin{enumerate}
    \item Ashwot Acharya
    \item Bishesh Bohora 
    \item Supreme Chaudhary
\end{enumerate}
in partial fulfillment of the requirements for the degree of B.Sc. in Computational Mathematics, Department of Mathematics, Kathmandu University, Dhulikhel, Nepal.

\vspace{3em}

\noindent
\begin{minipage}{0.45\textwidth}
\rule{6cm}{0.5pt}\\
\textbf{M.r K.B Manandhar }\\
Assistant Professor\\
Department of Mathematics,\\
School of Science\\ Kathmandu University,\\
Dhulikhel, Kavre, Nepal\\
Date: August, 2025

\end{minipage}


\vspace{2.5em}

\noindent
\\ \\ 
\textbf{APPROVED BY:}\\
I hereby declare that the candidate qualifies to submit this report of \textbf{Working Principles of Proof Assistants and Formalization of some proofs in Agda} to the Department of Mathematics.
\\
\vspace{1.7em}
\\
\noindent
\rule{6cm}{0.5pt}\\ \\
\textbf{Head of Department }\\
Department of Mathematics\\
School of Science\\
Kathmandu University\\
Date: August, 2025

\vspace{2em}

\begin{center}
   {\small ii}
\end{center}
\clearpage

\addcontentsline{toc}{section}{\textbf{ABSTRACT}}  
\clearpage

\begin{center}
    \textbf{\LARGE ACKNOWLEDGMENTS}
\end{center}
    First and foremost, we would like to thank our supervisor Mr K.B Manandhar sir for guiding us through this research project.
Their feedback and suggestions helped us overcome numerous challenges and shaped
our understanding of the subject matter.


\clearpage

\begin{abstract}
This report explores the theoretical foundations and working principles of proof assistants, with a focus on Agda. It introduces key concepts from logic, type theory, and the Curry–Howard correspondence that underlie formal verification. We discuss how proofs are treated as programs and propositions as types in dependently typed systems. A comparative study of proof assistants such as Agda, Coq (Rocq), and Lean is included, highlighting their kernel architectures and type-checking algorithms. Finally, we demonstrate formalization of selected logical proofs in Agda, reflecting on challenges and limitations encountered during implementation.
\end{abstract}
\clearpage



\tableofcontents
\newpage

\section{Introduction}

In 1998 Thomas C. Hales announced that he had proved the kepler conjecture
(Solane,1998) However the peer review took over 4 years especially due to the proof
being incredibely difficult to check, with over a dozen of mathematician to refree
the proof and although they were 99% certain it was not untill the proof became
formalized that they were able to completely validate the correctness of the proof,
which according to Thomas Hales, would have taken 20 person-year of manual work.
[Szpiro, G, 2003]

Proof assistants helps with formalization of mathematical proofs in computer which
enables for their verification digitally. Some exhaustive proofs may contain large
number of cases which is not feasible to write and verify manually and requires
computer assitance.
Such Proof assistants (systems) work by treating proofs as computational objects
and checking them using strict logical rules. To enable this, proofs must be writ-
ten in a formal language that removes ambiguity and allows machines to interpret
them accurately. Underlying this process is a theoretical framework—often type
theory—that defines how propositions and proofs relate to each other.
This method bridges programming and logic: writing a proof resembles writing a
program, and verifying it is like type-checking. By interpreting logic computation-
ally, proof assistants ensure that every proof is exact, complete, and verifiable by
a machine. This project invloves investigating this process. 

\subsection{Objectives}
\begin{enumerate}
    \item To explore the correspondence between Proofs and Programs, Type Theory and Intuitionstic Logic.
    \item To investigate a current exsisting proof assistants (Agda) and identify the mathematics behind it.
    \item To formalize some selected proofs in Agda and demonstrate verification process.
\end{enumerate}

\subsection{Limitations}
\begin{enumerate}
    \item This study fails to rigorously present the Type Checking Algorithm.
    \item Avoids formalization of complicated proofs.
\end{enumerate}




\section{Foundations}
This section sheds light upon some fundamental concept on which Proof Assistants work along with how a proof should be written so that it can be mechanically verified.
\subsection{Logic Foundations}
This works assumes prior knowledge of Propositional and Predicate Logic. And we refer to both together as \textbf{Classical}.
\subsubsection{Natural Deduction}
The propositions or formulas in Propositional Logic can be verified or proved simply by constructing their truth tables. But for logically complex propositions or propositions with many atomic statements, it becomes difficult to construct a truth table. With predicates, this becomes impossible. Therefore, to mitigate this we adhere to a basic set of inference rules with which we derive conclusions from assumptions in step by step, structured manner. The rule based system which allows us to reason about logical structure of propositions is known as \textbf{Natural Deduction}. \\
With the rules in Section 2.3 of \cite{Alrubyli2021}  we now present proofs of some propositions carried out with Natural Deduction for Classical Logic.

\newtheorem{proposition}{Proposition}[section] 
\newtheorem{example}{Example}[section]
\begin{proposition}
    \label{contra}
    \textbf{$(A \land\neg A) \to \bot $ }
  
    By negation introduction we can write $\neg A$ as $A \to \bot$

    $(A \land (A \to \bot)) \to \bot$

    \begin{prooftree}
        \AxiomC{$[A]$}
        \AxiomC{$[A \to \bot]$}
        \RightLabel{\scriptsize$\to$E}
        \BinaryInfC{$\bot$}
    \end{prooftree}
    
    

    

\end{proposition}

\begin{proposition}
    \label{lem}
    Proof for Law of Excluded Middle ($P \lor \neg P$)\\
    Note that Proposition \ref{contra} is used here.
    \begin{prooftree}
\AxiomC{$[P]$}
\RightLabel{\scriptsize$\lor$I$$}
\UnaryInfC{$P \lor \neg P$}
\AxiomC{$[\neg (P \lor \neg P)]$}
\RightLabel{\scriptsize$\bot$}
\BinaryInfC{$\bot$}
\RightLabel{\scriptsize$\neg I$}
\UnaryInfC{$\neg P$}
\RightLabel{\scriptsize$\lor$I$$}
\UnaryInfC{$P \lor \neg P$}
\AxiomC{$[\neg (P \lor \neg P)]$}
\RightLabel{\scriptsize$\bot$}
\BinaryInfC{$\bot$}
\RightLabel{\scriptsize$\neg$I$$}
\UnaryInfC{$\neg \neg (P \lor \neg P)$}
\RightLabel{\scriptsize$\neg\neg$E}
\UnaryInfC{$P \lor \neg P$}
\end{prooftree}
\end{proposition}



\begin{proposition}
    $$ \forall x (A(x) \to B(x) ) , A(s)  \vdash \exists  x B(x) $$

    \begin{prooftree}
        \AxiomC{$[ \forall x (A(x) \to B(x))]$}
        \AxiomC{$[A(s)]$}
        \RightLabel{\scriptsize $\forall E$}
        \BinaryInfC{$A(s) \to B(s)$}
        \RightLabel{\scriptsize $\to E$}
        \UnaryInfC{B(s)}
        \RightLabel{\scriptsize $\exists I$}
        \UnaryInfC{$\exists x B(x)$}
    \end{prooftree}

\end{proposition}

The \textbf{soundness} and \textbf{completeness} of this system are discussed in Section 3.1 and 3.2 \cite{Alrubyli2021}. 
\subsubsection{Intuitionstic Logic}
Intuitionstic Logic was introduced to formalize the constructive method to do mathematics. Unlike in Classical Logic a statement is True if we can construct a proof for it and to claim a statement is False, again a proof of its falsity is required. This allows the case that some statements are not provable. 
To show something exists one must provide an method or algorithm to construct it. Proof Assistants leverage this fact.
The constructive view of doing mathematics gives a stricter criteria. Intuitionstic  Logic can be obtained by restricting certain parts of Classical Logic, like the Law of Excluded Middle.

For inference rules for Natural Deduction in Intuitionstic Logic See 2.1 \cite{Pfenning2004}, here the language is slightly different from above, we have
\\
\textit{Terms} \quad $t ::= x \mid a \mid f(t_1, \ldots, t_n)$
\\
\textit{Propositions} \quad
$A ::= P(t_1, \ldots, t_n) \mid A_1 \land A_2 \mid A_1 \supset A_2 \mid A_1 \lor A_2 \mid \neg A \mid \bot \mid \top \mid \forall x. A \mid \exists x. A$

 The main focus is that this new set of rules does not contain the double negation rule which is present in what we introduced in Section 2.1.1. \textbf {Example \ref{lem}} uses the Double negation rule in its proof, which we don't have now. This agrees to that Law of Excluded Middle does not work in Intuitionstic Logic. The method of proof by contradiction also relies on this rule, so constructivists omit it.\\
These rules are revised with localized hypotheses i.e we use the above rules under a set of premises, and refer the derivation as "derived under a context". With introduction of contexts 
$$Contexts  \ \Gamma ::= .|\Gamma,u: A$$
[See 2.3 \cite{Pfenning2004}]


\subsection{$\lambda$ - Calculus and Type Theory} 

\subsubsection{ $\lambda$-Calculus}
It is a model of computation introduced by Alzano Church. It consists of construction and operations on lambda terms. 
Among the lambda terms we have,
\begin{enumerate}
    \item Variables : $x,y,z ...$ are lambda terms
    \item Application : If E,F are lambda terms EF is a lambda term 
    \item Abstraction : If E is a lambda term $\lambda x. E $ is a lambda term
\end{enumerate}
Therefore lambda calculus is a formal system involving Abstraction and Application of functions along with some reduction rules.
Abstraction is the definition of a anonymous function , for example \\
$$ \lambda x.x^2 $$

Now Application is calling that given function by applying it.

\begin{example}
\begin{align*}
 (\lambda x.x^2) 3\\
 3^2 \\
 9
\end{align*}
\end{example}
The functions can be constructed such that they can take multiple values too, say a function to compute sum of squares can be implemented with lambda calculus as

\begin{example}
    $$\lambda x \lambda y. x^2 +y^2$$
Its application is as 
$$(\lambda x \lambda y. x^2 +y^2) (3) (4)$$
$$(\lambda y. 3^2 + y^2)(4)$$
$$3^2+4^2$$
$$9+16$$
$$25$$
\end{example}

This is called \textbf{currying}.\\
The reduction rules are :

\begin{enumerate}
    \item $\alpha$-Conversion \\
    \indent The function remains the same if all bound variable is renamed.
    In above example $\lambda y. y^2$ does the same thing.

$\lambda x.t$ is same as $ \lambda y.t[x:=y]$
    \item $\beta$-Reduction\\
     This is substitution. During application all the instances of bound variable in the expression is replaced by the argument. Again referring above example $x^2$ becomes $3^2$.\\
     $(\lambda x.E) F$ is $E[x := F]$, where $E[x := F]$
\end{enumerate}
For comprehensive treatment of this topic, see \cite{Rojas2015}. And for the original formulation by Church \cite{}





\subsubsection{Type Theory}
Type Theory is a formal system that associates every object or \textbf{term} a \textbf{Type}. The earliest version of Type Theory was introduced by Russell to avoid paradoxes in Set Theory (like \textbf{Russell's Paradox}). Later with development of Simply Typed Lambda Calculus, this became important as a foundation of Programming Languages.\\

Unlike Sets, Types do not talk about the semantics but rather the structure or syntax only. For example, in Type theory, $1+2:\mathbb{N}$ we carry out the judgement that 1+2 is a Natural Number whereas while talking bout sets $1+2 \in \mathbb{N}$  means that 1+2 is inside $\mathbb{N}$. \\With types, we do not care what 1+2 means, the information we have is the operator '+' has a type $\mathbb{N} \times \mathbb{N}  \to \mathbb{N}$ and  $1:\mathbb{N}, 2:\mathbb{N}$ therefore the judgement  $1+2:\mathbb{N}$ follows. Whereas with sets, we proceed as $1+2=3\in \mathbb{N}$.\\

Note that verifying if a term a is of type A is decidable, i.e there is an algorithm for it. This process is called Typing or Type Checking. Proof Assistants leverage this for proof checking. Proof checking is decidable; proof finding not. \cite{Geuvers2009}\\


In simple type theory there are, 
\begin{itemize}
    \item \textbf{Base Types} : Primitive types which are not built from anything else, Eg: Boolean Type, Nat Type, $\bot$ or Empty Type etc. These are generally denoted by capital letters M,N,T etc. and we can carry out the judgement as\\
        a:A, a is term of Type A.\\ 
        
    \item \textbf{Arrow Types} : Also called as function type which take input of a type and return another. As we have discussed '+' has type $\mathbb{N} \to \mathbb{N}$. More generally if a function f takes input of type A and returns output of type B then, $f:A \to B$. In logic these are equivalent to implication. We will discuss about this correspondence later.
    
\end{itemize}

Which can be further extended as,
\begin{itemize}
    \item \textbf{Product Types} Product types are similar to Cartesian Products from Set Theory, the terms inhabiting the product type is a pair of terms from the involving types, $a:A, b:B $ then $ \left\langle a,b \right\rangle : A \times B$ .
    \item \textbf{Sum Type} This is similar to disjoint union with sets, therefore the term has one of the participating types. 
     $$a:A, b:B, a:A+B, b:A+B$$

    
\end{itemize}
\subsubsection{Simply Typed Lambda Calculus}
 We have already discussed about the Lambda Calculus as well as Types, now we assign a type to each lambda term. The functions in Untyped lambda Calculus are too general. In Example 2.5 we did not mention what squaring means, can we apply it to some arbitary type of data, what will the function return, these concerns remain unanswered. But when we assign every term a type, it can be assigned what can the function take and return.
 \begin{itemize}
    \item Variables  x:T , a variable which has a type T
    \item Abstraction $\lambda x:M.t:T$ , the function takes an input of type M and returns t of type T.
    \item Application $(\lambda x:M.t:T)(a:M)$
    


 \end{itemize}
 
 We present a typed version of Example 2.5\\
 \begin{example}
    $$\lambda x:\mathbb{N}.x^2:\mathbb{N}$$
    Note that now this function can only take natural numbers,\\
    Application
    $$(\lambda x:\mathbb{N}.x^2:\mathbb{N})(3)$$
    which gives, along with the judgement
    $$3^2:\mathbb{N}$$
 \end{example}

\subsubsection{Dependent Type Theory and Dependently Typed $\lambda$-Calculus}
In this extension of theory of types, we allow types to depend upon some value. For example, modeling vectors with types, we require it to depend on Natural number for its dimension. 
u:Vec(n) means u is a vector type with n dimension and n:$\mathbb{N}$. 
This can be taken as a function type with $Vec:\mathbb{N} \to Type$ , which takes a type of natural number as input and returns a type. This allows indexing of types and is useful for representing predicates.
And similarly as with simply typed $\lambda$-Calculus we can have lambda terms with dependent types. 

\subsection{Proof Terms and The Curry Howard Correspondence}
    Let us treat every proposition or Logical Formula as a Type, and their proofs as the term inhabiting it. Intuitionstically, we interpret a proposition being true if we present a proof for it. Here, it will be true if there is a term (proof) inhabiting the type (proposition).
    p:P is now interpreted as p is a proof of P. In \cite{How} the strong correspondence between intuitionstic derivation and lambda terms was mentioned. In essence the corrrespondence is as follows,
    \begin{table}[h]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Logic}                & \textbf{Computation}         & \textbf{Type Theory}             \\ \hline
Proposition                  & Type                         & Type                             \\ \hline
Proof                        & Program                      & Term                             \\ \hline
Proof Normalization          & Program Evaluation           & Reduction                        \\ \hline
Implication ($A \rightarrow B$) & Function Type ($A \to B$)    & $\lambda$-abstraction            \\ \hline
Conjunction ($A \land B$)    & Product Type ($A \times B$)  & Pairing                          \\ \hline
Disjunction ($A \lor B$)     & Sum Type ($A + B$)           & Tagged union                     \\ \hline
Falsehood ($\bot$)           & Empty Type                   & No term                          \\ \hline
Truth ($\top$)               & Unit Type                    & Singleton term                   \\ \hline
Negation ($\neg A$)          & $A \to \bot$                 & Function to empty type           \\ \hline
Universal Quantifier ($\forall x. A(x)$) & Dependent Product ($\Pi x : A. B(x)$) & Function over types \\ \hline
Existential Quantifier ($\exists x. A(x)$) & Dependent Sum ($\Sigma x : A. B(x)$) & Pair with dependent type \\ \hline


\end{tabular}
\caption{Curry–Howard Correspondence: Logic, Computation, and Type Theory}
\end{table}\\
The use of dependent product and sum for the Quantifier highlights the necessity of Dependent Type Theory. The rules  (Proof Terms only), equivalent to Deduction rules of Intuitionstic Logic are in Section 2.4 of \cite{Pfenning2004}. Note that this does not contain the rule for predicates. While writing a proof in a proof assistant our reasoning follows deduction rules of this kind. 
Then to write a  program (equivalent to proof) of the proposition $A \to B \to A$, we need to construct a function that takes term of type A , term of type B and returns term of type A, that is $\lambda a{:}A.\lambda b{:}B.t{:}A $ which proceeds as
\begin{proposition}
    $A \to B \to A$
   \begin{prooftree}
  \AxiomC{}
  \RightLabel{\scriptsize var}
  \UnaryInfC{$a{:}A,\ b{:}B \vdash a : A$}
  \RightLabel{\scriptsize lam}
  \UnaryInfC{$a{:}A \vdash \lambda b{:}B.\ a : B \rightarrow A$}
  \RightLabel{\scriptsize lam}
  \UnaryInfC{$\vdash \lambda a{:}A.\lambda b{:}B.\ a : A \rightarrow B \rightarrow A$}
\end{prooftree}
\end{proposition}



 \subsection{Martin-Löf Type Theory }
    Martin-Löf Type Theory is the formal logic system that was developed to support constructive mathematics. It's often referred to as Intuitionstic Type Theory. It carries the use of dependent types and is the backbone of Proof Assistants.\\
        The following types are also valid in this system.
        \begin{itemize}
            \item $\prod$-Type : The dependent function type, as mentioned in Table 1. it supports the interpretation of Universal Quantifier.
            \item $\sum$-Type : The dependent sum type, equivalent to the Existential Quantifier.
            \item Identity Type : Equality itself is internalized as a type in this system. Hence, we can judge if two terms are the same. By the correspondence, proofs are terms then this allows proof assistants to match proofs and declare their Equality.
            
        \end{itemize}
        Furthermore, We also have \textbf{Type Universes}, Every Type itself can be assigned a Type. This creates a hierarchy of types. For example, $1:\mathbb{N},\mathbb{N}:Type:...$, The number 1 has type Natural, then Natural has a type called Type, which itself can have another type. Not to be interpreted as , a set being contained in another set, this gives rise to paradoxes. But rather take it as hierarchy of Universes. From this we can talk about Types themselves within our system, and  allow proof assistants to safely handle abstraction over types.\\
        The results from  \cite{martinlof1972intuitionistic_theory} where this system was first introduced by Martin Löf, will be mentioned as necessary.
        
        .

\section{General Architecture of Proof Assistants}
The proof assistants follow a general architecture that adopts a design that seperates tiny,trusted kernel from progressively less trusted outer layer[]
\begin{figure}[h]
\centering
\begin{tabular}{|c|}
\hline
\textbf{User Interfaces} (VS Code, Proof General, CoqIDE, etc.) \\\hline
\textbf{Elaborator / Front-End}\\
\hline
\textbf{Tactic Engine \& Automation}\\
\hline
\textbf{Kernel (Type Checker + Inference Rules)}\\
\hline
\textbf{Logical Foundations (CIC, HOL, MLTT, …)}\\
\hline
\end{tabular}
\caption{Standard proof-assistant layer cake.}
\label{fig:layers}
\end{figure}


\subsection{The kernel} 
At the heart of any proof assistant lies the kernel, which is a minimal and formally verified component responsible for enforcing the programming logical rules. kernel implements the foundational calculus or logic and validates every proof
step by checking derivations against these rules. The kernel does't trust the computing base and checks for every proof , which ensures that the entire system depends on this critical component [Gordon, 1993][Paulson, 1987][The Coq Development Team, 2025].
\subsection{Tactic Engine}
Above the kernel layer is the tactic engine that assists users in constructing proofs interactively or automatically.
Tactics provide programmable strategies to decompose proof goals into simpler subgoals which can be easier to prove. 
Tactic implementations can become complex, but since any output they generate must be verified through the
kernel before acceptance,system integrity is maintained [Nipkow et al., 2002][Delahaye, 2000]. 


\subsection{Formal Proof language}
Proof assistants offer a dedicated programming language designed to express definitions, statements and proofs. These languages are typically Dependently typed,
and allows implicit argument . they are highly readable and rigorous. Integration with tactic scripting enables a smooth blend of automated and manual proof development [Barras et al.,
1997][Agda Team, 2023][Lean Development Group, 2024].

\subsection{Type checker and inference engine}
The type checker enforces logical consistency by validating the written expression , checking if it meets the system's typing
rules ,importantly preventing paradoxical constructs. Proof assistant often use bi-directional type checking and other 
complex inference algorithms.

\subsection{User Interface} 
Effective user interfaces (UIs) enable seamless interaction with the proof assistant. 
Modern UIs include integrated development environments (IDEs) or editor plugins that provide syntax highlighting, error diagnostics, real-time proof state visualization,
and automated tactic suggestion. Such interfaces significantly enhance productivity and make formal methods more accessible to a wider audience [CoqIDE, 2025][Isabelle/jEdit, 2023].
\subsection{Formal Libraries}
Proof assistants come with extensive, rigorously verified libraries that
encapsulate fundamental theories (e.g., arithmetic, set theory, algebra), supporting rapid development of
complex formalizations without reinventing foundational results.
These libraries grow continuously and provide a shared repository of reusable components vital for large-scale verification projects [Coq Standard Library, 2025][Mathlib, 2025][Isabelle Archive of Formal Proofs].


\begin{figure}[h!]
  \centering
  \includegraphics[width=0.7\textwidth]{fig/ui.png} 
  
\end{figure}
\cite{Geuvers20091}

\section{Upon Some Proof Assistants and Comparative Study}
\subsection{ Agda}
Agda  is a Dependently typed functional programming language and proof assistant. Extension of Martin-Lof's Type theory. (agda documentation) 
In Dependently typed programming language there is no clear distinction between types and values , and types can depend on arbitary values and may appear as results of ordinary functions. 
This feature of Dependently typed programs allows us to encode properties of values as type of proofs of that property, allowing us to use Dependent type programming as logic.  (Dependently Typed Programming in Agda) 

Every agda file has a top level module which corresponds to name of the file and the main programs goes inside the top level module.[]
Another key component of agda is pattern matching. Pattern matching is a mechanism for analysing the structure of values. When inductively defined  datatypes are introduced the
pattern matching becomes even more powerful as patten matching on one value can give the information about another value (thesis) 

\subsubsection {Kernel}
Agda's Kernel is written in Haskell. With no seperate tactic layer, the kernel is directly involved in all proof construction making it minimalistic yet more rigid. It tightly integrates normalization, which is a direct application of the Normalization Theorem in \cite{martinlof1972intuitionistic_theory}.

\subsubsection{ Type Checking algorithm}
Agda uses a bidirectional type checking algorithm grounded in Martin-Löf Type Theory, emphasizing manual proof construction and transparency. The checker alternates between inferring types for expressions and checking expressions against known types, supported by normalization by evaluation (NbE) to verify definitional equality. Unlike Lean or Coq, Agda offers minimal automation—there are no tactics, typeclass resolution, or automatic proof search. This makes it more predictable but also more labor-intensive. In contrast, Lean and Coq automate many aspects of type inference and proof construction via elaborators and tactics, with Coq relying on a trusted kernel and Lean integrating extensible unification and metaprogramming. Agda prioritizes explicitness and formal clarity, making it ideal for foundational studies in type theory.
\cite{depPUlf}
\subsection{Rocq}
Rocq formerly known as coq is another proof assistant or interactive theorem prover and lets you formalize mathematical proofs. becoming famous for the Formalization of four color theorem  .
Rocq is vastly different from agda in terms of proofs, While Agda is type theory based direct construction proof assistant Rocq on the other hand is tactic based. 
In Rocq users generate proofs by entering a series of tactics, which constitute steps of proofs. \cite{rocq_manual}
\subsubsection{Tactics}
    Mainly there are two ways of generating proofs forward reasoning and backward reasoning  \\ 
    In forward reasoning the simpler and smaller statements are proved and constructed to bigger statements and theorem, combining to prove the theorem at the end \\
    In Backward reasoning proofs begins with theorem statement and gradually transformed into sub-statement or goals which are proven. 
    Rcoq and Tactics heavily relies on Backward reasoning models.
    A tactic by itself may fully prove a goal or divide into sub goals to prove and most tactic in rocq require certain condition or elements to reduce a goal.
    some tactic are automatic and can solve complex goals\\ \cite{rocq_tactics}
    \subsubsection{Kernel}

    Rocq's kernel is based on Predicative Calculus of Cumulative Inductive Constructions(PCUIC) , a Dependently typed lambda calculus extended with various other rules and features. Rocq's core kernel converts all the notations and implicit arguments into core language which is the calculus of inductive construction. 
    the kernel wil verify the proof term built by the tactics . This type of seperation is called the "de Bruijn criterion" and makes it so that only the smaller components
    like the kernel is trusted and the entire program is checked by the kernel. Furthermore, its written in Coq itself (extracted to OCaml) i.e a Kernel being a program itself, its correctness is verified within it. \cite{rocq_core_language}

\subsubsection{Type checking Algorithm }
        In Rocq the syntaxes and typing rules are specified so that they remain mathematicaly precise and machine verifiable. For that the type system is first described declaratively, then refined to
        algorithmic specification. Rocq introduces a bi-directional infer and check type system that guides implementation.The checker is implemented in coq itsel. Much of type checking relies on deciding if two tpes are equivalent by Conversion or if one is the subtype of 
        other by cumulatively which is very challenging because these relations depend on reduction. The type checker is constructed as bi-directional algorithm and to ensure soundess the checker carries proof carrying code and returns the proof along with 
        the type checking decision. Every critical theoretic properity need for type checking is proved or assumed axiomatically to be true. The bidirectional type checking employed by Rocq is weak compared to Agda but it relies heavily on conversion. (Correct and Complete Type Checking and Certified Erasure for Coq, in Coq) \cite{type_checking}


\subsection{Lean} 
Lean theorem prover is a proof assistant developed by Leonardo Di-Moura at Microsoft in 2013. one way to prove theorem in lean is to 
build from assertion which follows the calculus of construction. Lean treats any two element say 
$ t1 \ t2: p $ to be equal, which is known as proof irrelevance. And allows for proposition as types logic. calculational proofs can also be written in lean and starts 
with the word calc.  \cite{lean_functional_programming}

Another way Like Rocq Lean can also relie on tactics. Tactics are useful for construction and destruction of data and there are many built in tactics avaible in lean. One of the major advantage of lean 
is that you can mix term-style and tactic-style proof writing and pass freely between the two. 
The ease of working with Lean is responsible for its popularity against other Proof Assistants.\cite{lean_theorem_proving}

\subsubsection{Kernel}
Lean's kernel is written in C++ (Lean 3) and C (Lean 4). The kernel much like Coq is based of Calculus of Inductive Constructions and employs conversion checking. Though its elaboration and tactic system is large, it is relatively less rigid but improves usability. Its performance based and offers flexibility.
Lean's kernel is implemented in two layers. The First layer contains the
type checker and APIs for creating and manipulating terms, declarations, and
the environment and the second layer provides additional components such as inductive families and quotient types. When the kernel is
instantiated, one selects which of these components should be used.
\cite{Lean}
\subsubsection{Type Checking Algorithm}
Likewise,the Bidirectional algorithm is applied here too. But the strength of Lean lies in its smart elaboration. Lean offers coercion, backtracking and overloading. 

\subsection{The Bidirectional Type Checking Algorithm }

At its core, this algorithm works on two modes 
\begin{itemize}
    \item Checking Mode $(\Gamma \vdash M \leftarrow A )$ Given the term M and an expectied type A , the task is to verify that M has type A. Its done when the type is known or can be known then propagated from the context.
    \item Synthesis (Inference) Mode  ($\Gamma \vdash M \rightarrow A$ ) When the type is known, the job is to infer it. That is synthesize unique type A for the term M. Since the type is not available from the context $\Gamma$ , it needs to be determined upwards.
    
\end{itemize}
The checking and infering in two directions (from or to context $\Gamma$) led it to be called Bidirectional .
\\



\clearpage

\section{Formalization of Some Proofs}


\subsection{Defining Natural Numbers, Equality and Proof of Assocaitive and Commutative Properties}
\begin{verbatim}


data N : Set where
    zero : N 
    suc : N -> N 

{-# BUILTIN NATURAL N #-}


--Equality
data _==_ { A : Set } ( x : A ) : A -> Set where 
    refl : x == x 

cong : {A B : Set } ( f : A -> B ) { x y : A}
    -> x == y
    -> f x == f y
cong f refl = refl 
sym : forall { A : Set } { x y : A}
    -> x == y
    -> y == x 
sym refl = refl

trans : { A : Set } { x y z : A}
    -> x == y
    -> y == z
    -> x == z

trans refl refl = refl 

{-# BUILTIN EQUALITY _==_ #-}

infix 4 _==_


--ADDITION

_+_ : N -> N -> N 
zero + x = x
suc x + y = suc(x + y)


--ZERO
zero-+ : ( a : N ) -> ( ( zero + a ) == a )
zero-+ a = refl

+-zero : ( a : N ) -> ( ( a + zero ) == a )
+-zero zero = refl
+-zero (suc a) = cong suc (+-zero a)

--LEMMA FOR COMMUTATIVITY
+-suc : forall x y -> x + suc y == suc (x + y)
+-suc zero y = refl
+-suc (suc x) y = cong suc (+-suc x y)


--ASSOCIATIVITY
assoc-+ : forall x y z -> (x + y) + z == x + (y + z)
assoc-+ zero y z = refl
assoc-+ (suc x) y z = cong suc (assoc-+ x y z)

--COMMUTATIVITY
+-comm : ( a b : N) -> ( ( a + b ) == ( b + a ) )
+-comm a zero = +-zero a 
+-comm a (suc b) = trans (+-suc a b) (cong suc (+-comm a b))


\end{verbatim}

\subsection{Formalizing Proposition 2.3 and 2.4 }
\begin{verbatim}
module props where

open import Agda.Primitive using (Level; lzero)

open import Data.Product using (Sigma; _,_)

variable
  l : Level
  X : Set l
  A B : X → Set l
  s : X


prop23 : (∀ x → A x → B x) → (s : X) → A s → Σ X B
prop23 allImp s aS = s , allImp s aS


prop24 : ∀ {A B : Set} -> A -> B -> A
prop24 a b = a
\end{verbatim}

\subsection{DeMorgan's Law}
\begin{verbatim}
    open import Agda.Primitive using (Level; lzero)
open import Data.Product using (_×_; _,_)
open import Data.Sum using (_⊎_; inj₁; inj₂)
open import Relation.Nullary using (Dec; yes; no)
open import Data.Empty using (⊥; ⊥-elim)
open import Relation.Nullary.Negation using (¬_)


--One Direction
deMorganOneWay : ∀ {ℓ} {P Q : Set ℓ} → (¬ P) ⊎ (¬ Q) → ¬ (P × Q)
deMorganOneWay (inj₁ np) (p , q) = np p
deMorganOneWay (inj₂ nq) (p , q) = nq q

--Converse, Requires Non Constructive Assumptions
deMorganOtherWay :
  ∀ {ℓ} {P Q : Set ℓ}
  → Dec P
  → Dec Q
  → ¬ (P × Q)
  → (¬ P) ⊎ (¬ Q)
deMorganOtherWay (yes p) _ notPQ = inj₂ (λ q → notPQ (p , q))
deMorganOtherWay (no np) (yes q) _ = inj₁ np
deMorganOtherWay (no np) (no nq) _ = inj₁ np  -- or inj₂ nq


\end{verbatim}
\subsection{Euclid's Theorem of Primes }



\subsection{Euclid's Algorithm's Proof}

\subsection{Attempt to Constructive Reals}






 

\section{Challenges and Workarounds}





% ======== References =========
\bibliographystyle{apalike} 
\bibliography{references.bib}

\end{document}
